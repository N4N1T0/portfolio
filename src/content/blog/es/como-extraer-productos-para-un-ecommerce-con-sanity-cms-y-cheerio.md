---
title: 'C√≥mo Extraer Productos para un E-commerce con Sanity CMS y Cheerio'
date: 2025-03-06
excerpt: 'Descubre c√≥mo extraer productos de un sitio de WordPress hacia Sanity CMS para una tienda en l√≠nea, utilizando Cheerio, Heroku CORS Anywhere y cron jobs.'
author: 'Adrian "Nano" Alvarez'
image: '../../../assets/blog/effect-of-mobile-apps-on-Consumer-and-Retailers--1024x538.webp'
imageAlt: 'El comercio electr√≥nico y la tecnolog√≠a juntos'
language: 'es'
---

## Introducci√≥n

Construir **sitios web de comercio electr√≥nico** siempre ha sido un desaf√≠o emocionante para m√≠, especialmente cuando trabajo en proyectos de alto impacto, como la venta de cosm√©ticos de una marca reconocida. Recientemente, me encomendaron la tarea de crear una tienda en l√≠nea para un cliente que era distribuidor oficial de una marca de cosm√©ticos llamada "Loreal" (es una broma üòÜ). El proyecto parec√≠a sencillo al principio, pero **hab√≠a un giro inesperado**: necesitaba automatizar el proceso de importaci√≥n de productos directamente en **Sanity CMS** desde un sitio externo basado en **WordPress**.

Habiendo trabajado en muchos sitios de e-commerce, siempre he abrazado nuevos desaf√≠os, pero este era √∫nico. Con un sitio fuente construido en WordPress y una **API p√∫blica** disponible, vi una oportunidad para crear un proceso de automatizaci√≥n que ahorrar√≠a mucho tiempo y esfuerzo al cliente. En esta publicaci√≥n, te explicar√© c√≥mo abord√© esta tarea, las herramientas que utilic√© y c√≥mo constru√≠ un sistema automatizado de importaci√≥n de productos eficiente, escalable y de bajo mantenimiento.

## Extrayendo los Datos

Para comenzar, necesitaba recopilar toda la informaci√≥n de los productos desde el sitio fuente. Como estaba basado en WordPress y ten√≠a una API p√∫blica expuesta (atenci√≥n a esto), pod√≠a obtener los nombres y enlaces de los productos. A primera vista, parec√≠a una tarea f√°cil: simplemente podr√≠a usar un bucle con par√°metros de b√∫squeda como `per_page` y `page` para paginar a trav√©s de todas las listas de productos.

```javascript
const API_URL = 'https://example.com/wp-json/wp/v2/products'

async function fetchAllProductLinks() {
  let allProductDetails = []
  let page = 1
  let products = []

  try {
    do {
      const response = await fetch(`${API_URL}?per_page=20&page=${page}`)
      products = response.data
      allProductDetails = allProductDetails.concat(
        products.map((product) => ({
          link: product.link,
          name: product.name
        }))
      )
      page++
    } while (products.length > 0)

    return allProductDetails
  } catch (error) {
    console.error('Error obteniendo enlaces y nombres de productos:', error)
  }
}
```

Con este c√≥digo, pude recopilar f√°cilmente todos los enlaces de productos. Pero el verdadero trabajo comenz√≥ cuando necesite extraer informaci√≥n detallada de cada p√°gina de producto individual. Aqu√≠ es donde **Cheerio** entr√≥ en juego.

Cheerio es una biblioteca r√°pida y liviana que imita jQuery, lo que la hace perfecta para extraer contenido HTML de una p√°gina. La us√© para cargar cada p√°gina de producto y extraer detalles clave, como el nombre del producto, descripci√≥n, im√°genes y m√°s.

```javascript
const cheerio = require('cheerio')

async function scrapeProductDetails(url) {
  try {
    const { data } = await fetch(`https://cors-anywhere.herokuapp.com/` + url)
    const $ = cheerio.load(data)

    const productName = $('h1').text()
    const productDescription = $('meta[name="description"]').attr('content')
    const productImage = $('img.product-image').attr('src')

    return { productName, productDescription, productImage }
  } catch (error) {
    console.error('Error extrayendo detalles del producto:', error)
  }
}
```

En este punto, ten√≠a la mayor parte de los detalles de los productos, pero faltaba una pieza crucial de informaci√≥n: **el precio**. Mi cliente me proporcion√≥ un PDF que conten√≠a los precios de distribuidor. Para asegurarme de que los datos fueran precisos, necesitaba cruzar la informaci√≥n de los precios con la del PDF.

Aqu√≠ recurr√≠ a **ChatGPT** para ayudarme a extraer los detalles necesarios del PDF. Con un poco de **ingenier√≠a de prompts** (pronto escribir√© un art√≠culo sobre esto), pude crear un proceso que extra√≠a autom√°ticamente los nombres de los productos, c√≥digos de referencia y precios del PDF.

## Integraci√≥n con Sanity CMS

Con los datos validados y enriquecidos, era el momento de cargarlos en **Sanity CMS**. Utilic√© el m√©todo `.createIfNotExists()` del cliente de Sanity para crear registros de productos s√≥lo si no exist√≠an previamente. Esto me ayud√≥ a evitar duplicados y asegurarme de que siempre trabajaba con la informaci√≥n m√°s actualizada.

```javascript
const sanityClient = require('@sanity/client')

const client = sanityClient({
  projectId: 'your-project-id',
  dataset: 'production',
  token: 'your-token',
  useCdn: true
})

async function createProductInSanity(product) {
  try {
    await client.createIfNotExists({
      name: product.name,
      productDescription: product.description,
      productImage: product.image
    })
  } catch (error) {
    console.error('Error creando producto en Sanity:', error)
  }
}
```

Para evitar sobrecargar el servidor con demasiadas solicitudes, utilic√© **p-limit**, una peque√±a biblioteca que limita el n√∫mero de promesas concurrentes, asegurando que no alcanzara los l√≠mites de peticiones.

```javascript
const pLimit = require('p-limit')
const limit = pLimit(5)

const productPromises = products.map((product) =>
  limit(() => createProductInSanity(product))
)

await Promise.all(productPromises)
```

## Automatizaci√≥n

Para asegurarme de que el cat√°logo de productos estuviera siempre actualizado, configur√© un **cron job** que se ejecuta diariamente a las 00:01 AM.

```javascript
const cron = require('node-cron')
cron.schedule('0 1 * * *', async () => {
  console.log('Ejecutando proceso de actualizaci√≥n de productos...')
})
```

## Conclusi√≥n

Este proyecto demostr√≥ c√≥mo la automatizaci√≥n y las integraciones inteligentes pueden mejorar significativamente la gesti√≥n de productos en e-commerce. Al combinar Cheerio para el scraping, Sanity CMS para la gesti√≥n de contenido y Heroku CORS Anywhere para evitar problemas de CORS, cre√© un proceso eficiente y automatizado.
